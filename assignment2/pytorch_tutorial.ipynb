{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Basics\n",
    "### What is PyTorch?\n",
    "It is a **replacement for NumPy** to use the power of GPUs, and a **deep learning research platform** that provides maximum flexibility and speed ([source](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)).\n",
    "\n",
    "You can create a [PyTorch tensor](https://pytorch.org/docs/stable/tensors.html) in a similary way that you create a NumPy ndarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.3.1+cu92\n",
      "\n",
      "Create a zero ndarray in NumPy:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "Create a zero tensor in PyTorch:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(\"torch version:\", torch.__version__) # please use pytorch 1.0\n",
    "\n",
    "print('\\nCreate a zero ndarray in NumPy:')\n",
    "zero_np = np.zeros([2, 3])\n",
    "print(zero_np)\n",
    "print('\\nCreate a zero tensor in PyTorch:')\n",
    "zero_pt = torch.zeros([2,3])\n",
    "print(zero_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index into the tensor the same way you index a ndarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: zero_np[0,1]: 0.0\t(type: <class 'numpy.float64'>)\n",
      "torch: zero_pt[0,1]: tensor(0.)\t(type: <class 'torch.Tensor'> / shape: torch.Size([]))\n",
      "       zero_pt[0,1].item(): 0.0\t(type: <class 'float'>)\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy: zero_np[0,1]: {}\\t(type: {})\".format(str(zero_np[0,1]), type(zero_np[0,1])))\n",
    "print(\"torch: zero_pt[0,1]: {}\\t(type: {} / shape: {})\".format(str(zero_pt[0,1]), type(zero_pt[0,1]), zero_pt[0,1].shape))\n",
    "# Use \"item()\" to get a Python number from a single-valued tensor.\n",
    "print(\"       zero_pt[0,1].item(): {}\\t(type: {})\".format(zero_pt[0,1].item(), type(zero_pt[0,1].item())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ndarray can be turned into a tensor, and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn a ndarray into a tensor with \"torch.tensor()\":\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64)\n",
      "or \"torch.from_numpy():\"\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64)\n",
      "\n",
      "Turn a tensor into ndarray with \".numpy()\":\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Turn a ndarray into a tensor with \"torch.tensor()\":')\n",
    "zero_pt_from_np = torch.tensor(zero_np)\n",
    "print(zero_pt_from_np)\n",
    "print('or \"torch.from_numpy():\"')\n",
    "zero_pt_from_np = torch.from_numpy(zero_np)\n",
    "print(zero_pt_from_np)\n",
    "\n",
    "print('\\nTurn a tensor into ndarray with \".numpy()\":')\n",
    "zero_np_from_pt = zero_pt.numpy()\n",
    "print(zero_np_from_pt)\n",
    "print(type(zero_np_from_pt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design of PyTorch allows it to better utilize GPUs. Upon creation, a PyTorch tensor resides on the CPU. You can move a tensor across devices using `.to()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial device:\t'cpu'\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(2)\n",
    "print(\"Initial device:\\t'{}'\".format(t.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move to gpu:\t'cuda:0'\n"
     ]
    }
   ],
   "source": [
    "t = t.to('cuda:0')\n",
    "print(\"Move to gpu:\\t'{}'\".format(t.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back to cpu:\t'cpu'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.747064 , 0.8991467], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.to('cpu')\n",
    "print(\"Back to cpu:\\t'{}'\".format(t.device))\n",
    "# Why bother?\n",
    "t.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training an MNIST Classifier\n",
    "=====\n",
    "## Custom Dataset, Model Checkpointing, and Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn            # containing various building blocks for your neural networks\n",
    "import torch.optim as optim      # implementing various optimization algorithms\n",
    "import torch.nn.functional as F  # a lower level (compared to torch.nn) interface\n",
    "\n",
    "# torchvision: popular datasets, model architectures, and common image transformations for computer vision.\n",
    "import torchvision\n",
    "# transforms: transformations useful for image processing\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom Dataset\n",
    "PyTorch has many built-in datasets such as MNIST and CIFAR. In this tutorial, we demonstrate how to write your own dataset by implementing a custom MNIST dataset class. Use [this link](https://github.com/myleott/mnist_png/blob/master/mnist_png.tar.gz?raw=true) to download the mnist png dataset.\n",
    "\n",
    "If you are on GCloud, you can run these commands:\n",
    "\n",
    "`wget https://github.com/myleott/mnist_png/blob/master/mnist_png.tar.gz?raw=true`\n",
    "\n",
    "`mv mnist_png.tar.gz?raw=true mnist_png.tar.gz`\n",
    "\n",
    "`tar -xzf mnist_png.tar.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for MNIST.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 transform=None,\n",
    "                 preload=False):\n",
    "        \"\"\" Intialize the MNIST dataset\n",
    "        \n",
    "        Args:\n",
    "            - root: root directory of the dataset\n",
    "            - tranform: a custom tranform function\n",
    "            - preload: if preload the dataset into memory\n",
    "        \"\"\"\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # read filenames\n",
    "        for i in range(10):\n",
    "            filenames = glob.glob(osp.join(root, str(i), '*.png'))\n",
    "            for fn in filenames:\n",
    "                self.filenames.append((fn, i)) # (filename, label) pair\n",
    "                \n",
    "        # if preload dataset into memory\n",
    "        if preload:\n",
    "            self._preload()\n",
    "            \n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def _preload(self):\n",
    "        \"\"\"\n",
    "        Preload dataset to memory\n",
    "        \"\"\"\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for image_fn, label in self.filenames:            \n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            self.images.append(image.copy())\n",
    "            # avoid too many opened files bug\n",
    "            image.close()\n",
    "            self.labels.append(label)\n",
    "\n",
    "    # probably the most important to customize.\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        if self.images is not None:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            # If on-demand data loading\n",
    "            image_fn, label = self.filenames[index]\n",
    "            image = Image.open(image_fn)\n",
    "            \n",
    "        # May use transform function to transform samples\n",
    "        # e.g., random crop, whitening\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # return image and label\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MNIST dataset. \n",
    "# transforms.ToTensor() automatically converts PIL images to\n",
    "# torch tensors with range [0, 1]\n",
    "trainset = MNIST(\n",
    "    root='mnist_png/training',\n",
    "    preload=True, transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "# We want the dataset to be shuffled during training.\n",
    "trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n",
    "\n",
    "# Load the testset\n",
    "testset = MNIST(\n",
    "    root='mnist_png/testing',\n",
    "    preload=True, transform=transforms.ToTensor(),\n",
    ")\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset)) # len = 60000\n",
    "print(len(testset))  # len = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) tensor(2) tensor(9) tensor(0) tensor(9) tensor(2) tensor(1) tensor(4) tensor(1) tensor(0) tensor(8) tensor(0) tensor(5) tensor(7) tensor(1) tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainset_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Conv Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "        #        dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        \n",
    "        # Linear(in_features, out_features, bias=True)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "        # MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        # ReLU(inplace=False)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Note: the following two ways for max pooling / relu are equivalent.\n",
    "        # 1) with torch.nn.functional:\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        # 2) with torch.nn:\n",
    "        x = self.relu(self.max_pool(self.conv2_drop(self.conv2(x))))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(epoch, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        start = time()\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            # bring data to the computing device, e.g. GPU\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # compute loss: negative log-likelihood\n",
    "            loss = F.nll_loss(output, target)\n",
    "            \n",
    "            # backward pass\n",
    "            # clear the gradients of all tensors being optimized.\n",
    "            optimizer.zero_grad()\n",
    "            # accumulate (i.e. add) the gradients from this forward pass\n",
    "            loss.backward()\n",
    "            # performs a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            iteration += 1\n",
    "            \n",
    "        end = time()\n",
    "        print('{:.2f}s'.format(end-start))\n",
    "        test() # evaluate at the end of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()  # set evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(testset_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testset_loader.dataset),\n",
    "        100. * correct / len(testset_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.297776\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.297734\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.290660\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.279495\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.212703\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.049824\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 1.855791\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 1.562130\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 1.434023\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 1.000431\n",
      "2.96s\n",
      "\n",
      "Test set: Average loss: 0.7008, Accuracy: 8279/10000 (83%)\n",
      "\n",
      "Train Epoch: 1 [3968/60000 (7%)]\tLoss: 0.444930\n",
      "Train Epoch: 1 [10368/60000 (17%)]\tLoss: 0.399854\n",
      "Train Epoch: 1 [16768/60000 (28%)]\tLoss: 0.390900\n",
      "Train Epoch: 1 [23168/60000 (39%)]\tLoss: 0.371772\n",
      "Train Epoch: 1 [29568/60000 (49%)]\tLoss: 0.500915\n",
      "Train Epoch: 1 [35968/60000 (60%)]\tLoss: 0.266857\n",
      "Train Epoch: 1 [42368/60000 (71%)]\tLoss: 0.183061\n",
      "Train Epoch: 1 [48768/60000 (81%)]\tLoss: 0.325126\n",
      "Train Epoch: 1 [55168/60000 (92%)]\tLoss: 0.310265\n",
      "3.00s\n",
      "\n",
      "Test set: Average loss: 0.2423, Accuracy: 9292/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [1536/60000 (3%)]\tLoss: 0.158915\n",
      "Train Epoch: 2 [7936/60000 (13%)]\tLoss: 0.209696\n",
      "Train Epoch: 2 [14336/60000 (24%)]\tLoss: 0.241129\n",
      "Train Epoch: 2 [20736/60000 (35%)]\tLoss: 0.249869\n",
      "Train Epoch: 2 [27136/60000 (45%)]\tLoss: 0.230930\n",
      "Train Epoch: 2 [33536/60000 (56%)]\tLoss: 0.183611\n",
      "Train Epoch: 2 [39936/60000 (67%)]\tLoss: 0.151994\n",
      "Train Epoch: 2 [46336/60000 (77%)]\tLoss: 0.204085\n",
      "Train Epoch: 2 [52736/60000 (88%)]\tLoss: 0.142550\n",
      "Train Epoch: 2 [59136/60000 (99%)]\tLoss: 0.258133\n",
      "2.97s\n",
      "\n",
      "Test set: Average loss: 0.1622, Accuracy: 9485/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [5504/60000 (9%)]\tLoss: 0.064761\n",
      "Train Epoch: 3 [11904/60000 (20%)]\tLoss: 0.172867\n",
      "Train Epoch: 3 [18304/60000 (30%)]\tLoss: 0.120763\n",
      "Train Epoch: 3 [24704/60000 (41%)]\tLoss: 0.064169\n",
      "Train Epoch: 3 [31104/60000 (52%)]\tLoss: 0.105164\n",
      "Train Epoch: 3 [37504/60000 (62%)]\tLoss: 0.064969\n",
      "Train Epoch: 3 [43904/60000 (73%)]\tLoss: 0.054163\n",
      "Train Epoch: 3 [50304/60000 (84%)]\tLoss: 0.143456\n",
      "Train Epoch: 3 [56704/60000 (94%)]\tLoss: 0.139970\n",
      "2.93s\n",
      "\n",
      "Test set: Average loss: 0.1203, Accuracy: 9650/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [3072/60000 (5%)]\tLoss: 0.059348\n",
      "Train Epoch: 4 [9472/60000 (16%)]\tLoss: 0.119847\n",
      "Train Epoch: 4 [15872/60000 (26%)]\tLoss: 0.133698\n",
      "Train Epoch: 4 [22272/60000 (37%)]\tLoss: 0.266899\n",
      "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.062714\n",
      "Train Epoch: 4 [35072/60000 (58%)]\tLoss: 0.078703\n",
      "Train Epoch: 4 [41472/60000 (69%)]\tLoss: 0.109738\n",
      "Train Epoch: 4 [47872/60000 (80%)]\tLoss: 0.173844\n",
      "Train Epoch: 4 [54272/60000 (90%)]\tLoss: 0.157095\n",
      "2.88s\n",
      "\n",
      "Test set: Average loss: 0.1035, Accuracy: 9680/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(5)  # train 5 epochs should get you to about 97% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save the model (model checkpointing)\n",
    "\n",
    "Now we have trained a model! Obviously we do not want to retrain the model everytime we want to use it. Plus if you are training a super big model, you probably want to save checkpoint periodically so that you can always fall back to the last checkpoint in case something bad happened or you simply want to test models at different training iterations.\n",
    "\n",
    "Model checkpointing is fairly simple in PyTorch. First, we define a helper function that can save a model to the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    # state_dict: a Python dictionary object that:\n",
    "    # - for a model, maps each layer to its parameter tensor;\n",
    "    # - for an optimizer, contains info about the optimizers states and hyperparameters used.\n",
    "    state = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3039, Accuracy: 1009/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a brand new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# Testing -- you should get a pretty poor performance since the model hasn't learned anything yet.\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a training loop with model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save(epoch, save_interval, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            # different from before: saving model checkpoints\n",
    "            if iteration % save_interval == 0 and iteration > 0:\n",
    "                save_checkpoint('mnist_png/mnist-%i.pth' % iteration, model, optimizer)\n",
    "            iteration += 1\n",
    "        test()\n",
    "    \n",
    "    # save the final model\n",
    "    save_checkpoint('mnist_png/mnist-%i.pth' % iteration, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.306609\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.311068\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.292341\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.273087\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.270994\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.219981\n",
      "model saved to mnist_png/mnist-500.pth\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.041701\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 1.903808\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 1.502922\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 1.079106\n",
      "\n",
      "Test set: Average loss: 0.7464, Accuracy: 8255/10000 (83%)\n",
      "\n",
      "Train Epoch: 1 [3968/60000 (7%)]\tLoss: 0.495041\n",
      "model saved to mnist_png/mnist-1000.pth\n",
      "Train Epoch: 1 [10368/60000 (17%)]\tLoss: 0.621133\n",
      "Train Epoch: 1 [16768/60000 (28%)]\tLoss: 0.556382\n",
      "Train Epoch: 1 [23168/60000 (39%)]\tLoss: 0.254197\n",
      "Train Epoch: 1 [29568/60000 (49%)]\tLoss: 0.373339\n",
      "Train Epoch: 1 [35968/60000 (60%)]\tLoss: 0.508984\n",
      "model saved to mnist_png/mnist-1500.pth\n",
      "Train Epoch: 1 [42368/60000 (71%)]\tLoss: 0.561251\n",
      "Train Epoch: 1 [48768/60000 (81%)]\tLoss: 0.299027\n",
      "Train Epoch: 1 [55168/60000 (92%)]\tLoss: 0.283355\n",
      "\n",
      "Test set: Average loss: 0.2521, Accuracy: 9232/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [1536/60000 (3%)]\tLoss: 0.281905\n",
      "Train Epoch: 2 [7936/60000 (13%)]\tLoss: 0.291216\n",
      "model saved to mnist_png/mnist-2000.pth\n",
      "Train Epoch: 2 [14336/60000 (24%)]\tLoss: 0.210150\n",
      "Train Epoch: 2 [20736/60000 (35%)]\tLoss: 0.250386\n",
      "Train Epoch: 2 [27136/60000 (45%)]\tLoss: 0.462630\n",
      "Train Epoch: 2 [33536/60000 (56%)]\tLoss: 0.312988\n",
      "Train Epoch: 2 [39936/60000 (67%)]\tLoss: 0.088961\n",
      "model saved to mnist_png/mnist-2500.pth\n",
      "Train Epoch: 2 [46336/60000 (77%)]\tLoss: 0.202680\n",
      "Train Epoch: 2 [52736/60000 (88%)]\tLoss: 0.186350\n",
      "Train Epoch: 2 [59136/60000 (99%)]\tLoss: 0.091719\n",
      "\n",
      "Test set: Average loss: 0.1678, Accuracy: 9503/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [5504/60000 (9%)]\tLoss: 0.122802\n",
      "Train Epoch: 3 [11904/60000 (20%)]\tLoss: 0.176740\n",
      "model saved to mnist_png/mnist-3000.pth\n",
      "Train Epoch: 3 [18304/60000 (30%)]\tLoss: 0.096132\n",
      "Train Epoch: 3 [24704/60000 (41%)]\tLoss: 0.357604\n",
      "Train Epoch: 3 [31104/60000 (52%)]\tLoss: 0.151603\n",
      "Train Epoch: 3 [37504/60000 (62%)]\tLoss: 0.228213\n",
      "Train Epoch: 3 [43904/60000 (73%)]\tLoss: 0.230166\n",
      "model saved to mnist_png/mnist-3500.pth\n",
      "Train Epoch: 3 [50304/60000 (84%)]\tLoss: 0.140330\n",
      "Train Epoch: 3 [56704/60000 (94%)]\tLoss: 0.117771\n",
      "\n",
      "Test set: Average loss: 0.1311, Accuracy: 9594/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [3072/60000 (5%)]\tLoss: 0.041411\n",
      "Train Epoch: 4 [9472/60000 (16%)]\tLoss: 0.258210\n",
      "Train Epoch: 4 [15872/60000 (26%)]\tLoss: 0.157217\n",
      "model saved to mnist_png/mnist-4000.pth\n",
      "Train Epoch: 4 [22272/60000 (37%)]\tLoss: 0.088285\n",
      "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.154736\n",
      "Train Epoch: 4 [35072/60000 (58%)]\tLoss: 0.143422\n",
      "Train Epoch: 4 [41472/60000 (69%)]\tLoss: 0.099700\n",
      "Train Epoch: 4 [47872/60000 (80%)]\tLoss: 0.173551\n",
      "model saved to mnist_png/mnist-4500.pth\n",
      "Train Epoch: 4 [54272/60000 (90%)]\tLoss: 0.121460\n",
      "\n",
      "Test set: Average loss: 0.1063, Accuracy: 9667/10000 (97%)\n",
      "\n",
      "model saved to mnist_png/mnist-4690.pth\n"
     ]
    }
   ],
   "source": [
    "train_save(5, save_interval=500, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from mnist_png/mnist-4690.pth\n",
      "\n",
      "Test set: Average loss: 0.1063, Accuracy: 9667/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# load from the final checkpoint\n",
    "load_checkpoint('mnist_png/mnist-4690.pth', model, optimizer)\n",
    "# should give you the final model accuracy\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-tune a model\n",
    "\n",
    "Sometimes you want to fine-tune a pretrained model instead of training a model from scratch. For example, if you want to train a model on a new dataset that contains natural images. To achieve the best performance, you can start with a model that's fully trained on ImageNet and fine-tune the model.\n",
    "\n",
    "Finetuning a model in PyTorch is super easy! First, let's find out what we saved in a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
     ]
    }
   ],
   "source": [
    "# What's in a state dict?\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the fc layers\n",
    "\n",
    "Now say we want to load the conv layers from the checkpoint and train the fc layers. We can simply load a subset of the state dict with the selected names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter variables to load: 4\n",
      "Number of parameter variables in the model: 8\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('mnist_png/mnist-4690.pth')\n",
    "states_to_load = {}\n",
    "for name, param in checkpoint['state_dict'].items():\n",
    "    if name.startswith('conv'):\n",
    "        # only load the conv layers\n",
    "        states_to_load[name] = param\n",
    "print(\"Number of parameter variables to load:\", len(states_to_load))\n",
    "\n",
    "# Construct a new state_dict in which the layers we want\n",
    "# to import from the checkpoint is updated with the parameters\n",
    "# from the checkpoint\n",
    "model = Net().to(device)\n",
    "model_state = model.state_dict()\n",
    "print(\"Number of parameter variables in the model:\", len(model_state))\n",
    "model_state.update(states_to_load)\n",
    "        \n",
    "model.load_state_dict(model_state)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.5789, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 3.294551\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.389612\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.038293\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 1.028128\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.784630\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.768171\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.902026\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.986785\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.589040\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.582019\n",
      "3.06s\n",
      "\n",
      "Test set: Average loss: 0.2574, Accuracy: 9282/10000 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test() # without fine-tuning.\n",
    "\n",
    "train(1)  # training 1 epoch will get you to 93%!\n",
    "# As a comparison, training from scratch for 1 epoch gets about ~80% test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pretrained weights in a different model\n",
    "\n",
    "We can even use the pretrained conv layers in a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallNet, self).__init__()\n",
    "        # same conv layers\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        # fewer FC layers\n",
    "        self.fc1 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = SmallNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3089, Accuracy: 1006/10000 (10%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('mnist_png/mnist-4690.pth')\n",
    "states_to_load = {}\n",
    "for name, param in checkpoint['state_dict'].items():\n",
    "    if name.startswith('conv'):\n",
    "        states_to_load[name] = param\n",
    "\n",
    "# Construct a new state dict in which the layers we want\n",
    "# to import from the checkpoint is update with the parameters\n",
    "# from the checkpoint\n",
    "model_state = model.state_dict()\n",
    "model_state.update(states_to_load)\n",
    "        \n",
    "test()\n",
    "\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 6.141425\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.423519\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.455093\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.402700\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.363984\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.184746\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.293525\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.265453\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.253889\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.388781\n",
      "3.06s\n",
      "\n",
      "Test set: Average loss: 0.1605, Accuracy: 9519/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(1)  # training 1 epoch will get you to ~93%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up your code with nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetSeq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetSeq, self).__init__()\n",
    "\n",
    "        # conv layers: feature extractor\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.Dropout2d(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # fc layers: classifier\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(320, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(50, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc_layers(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = NetSeq().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.292424\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.291882\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.287313\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.279325\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.214175\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.053960\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.020224\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 1.719584\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 1.325080\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 1.154942\n",
      "3.03s\n",
      "\n",
      "Test set: Average loss: 0.7356, Accuracy: 8206/10000 (82%)\n",
      "\n",
      "Train Epoch: 1 [3968/60000 (7%)]\tLoss: 0.453940\n",
      "Train Epoch: 1 [10368/60000 (17%)]\tLoss: 0.485988\n",
      "Train Epoch: 1 [16768/60000 (28%)]\tLoss: 0.475125\n",
      "Train Epoch: 1 [23168/60000 (39%)]\tLoss: 0.239425\n",
      "Train Epoch: 1 [29568/60000 (49%)]\tLoss: 0.238649\n",
      "Train Epoch: 1 [35968/60000 (60%)]\tLoss: 0.219279\n",
      "Train Epoch: 1 [42368/60000 (71%)]\tLoss: 0.305218\n",
      "Train Epoch: 1 [48768/60000 (81%)]\tLoss: 0.265227\n",
      "Train Epoch: 1 [55168/60000 (92%)]\tLoss: 0.302981\n",
      "3.05s\n",
      "\n",
      "Test set: Average loss: 0.2394, Accuracy: 9304/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [1536/60000 (3%)]\tLoss: 0.295856\n",
      "Train Epoch: 2 [7936/60000 (13%)]\tLoss: 0.296748\n",
      "Train Epoch: 2 [14336/60000 (24%)]\tLoss: 0.279908\n",
      "Train Epoch: 2 [20736/60000 (35%)]\tLoss: 0.209395\n",
      "Train Epoch: 2 [27136/60000 (45%)]\tLoss: 0.279042\n",
      "Train Epoch: 2 [33536/60000 (56%)]\tLoss: 0.321413\n",
      "Train Epoch: 2 [39936/60000 (67%)]\tLoss: 0.176725\n",
      "Train Epoch: 2 [46336/60000 (77%)]\tLoss: 0.074392\n",
      "Train Epoch: 2 [52736/60000 (88%)]\tLoss: 0.320470\n",
      "Train Epoch: 2 [59136/60000 (99%)]\tLoss: 0.241949\n",
      "2.92s\n",
      "\n",
      "Test set: Average loss: 0.1642, Accuracy: 9501/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [5504/60000 (9%)]\tLoss: 0.359926\n",
      "Train Epoch: 3 [11904/60000 (20%)]\tLoss: 0.240459\n",
      "Train Epoch: 3 [18304/60000 (30%)]\tLoss: 0.221581\n",
      "Train Epoch: 3 [24704/60000 (41%)]\tLoss: 0.265236\n",
      "Train Epoch: 3 [31104/60000 (52%)]\tLoss: 0.071581\n",
      "Train Epoch: 3 [37504/60000 (62%)]\tLoss: 0.139121\n",
      "Train Epoch: 3 [43904/60000 (73%)]\tLoss: 0.064902\n",
      "Train Epoch: 3 [50304/60000 (84%)]\tLoss: 0.183760\n",
      "Train Epoch: 3 [56704/60000 (94%)]\tLoss: 0.095603\n",
      "3.08s\n",
      "\n",
      "Test set: Average loss: 0.1220, Accuracy: 9633/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [3072/60000 (5%)]\tLoss: 0.054818\n",
      "Train Epoch: 4 [9472/60000 (16%)]\tLoss: 0.051685\n",
      "Train Epoch: 4 [15872/60000 (26%)]\tLoss: 0.102028\n",
      "Train Epoch: 4 [22272/60000 (37%)]\tLoss: 0.072713\n",
      "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.253630\n",
      "Train Epoch: 4 [35072/60000 (58%)]\tLoss: 0.180776\n",
      "Train Epoch: 4 [41472/60000 (69%)]\tLoss: 0.161412\n",
      "Train Epoch: 4 [47872/60000 (80%)]\tLoss: 0.092579\n",
      "Train Epoch: 4 [54272/60000 (90%)]\tLoss: 0.088074\n",
      "2.96s\n",
      "\n",
      "Test set: Average loss: 0.0968, Accuracy: 9712/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
